server:
  admin_addr: "0.0.0.0:8001" # the admin entrypoint for prometheus and pprof

  # settings for consummer part
  consume_routines: 2 # number of the goroutines, for consuming messages from kafka(default 2)
  consume_buffer: 50 # queue size for all consumer goroutines(default 100)

  # setttings for engine part
  engine_routines: 2 # number of the goroutines, for handling messages(default 2)
  engine_batch: 5 # batch size for collecting(default 10)
  engine_buffer: 10 # queue size for all engine goroutines(default 100)
  engine_delay_time: 2 # waiting for reading channel when receive exit signals(default 2s)
  engine_refresh_time: 5 # use a timer to refresh the unreached buffer to storage periodly(default 5s)

  # setttings for storage part
  storage_routines: 2 # number of the goroutines, for batch inserting(default 2)
  storage_delay_time: 4 # waiting for reading channel when receive exit signals(default 4s)
  storage_wait_time: 2 # the waiting time for insertion when database happens exception(default 5s)

kafka:
  brokers: ["192.168.0.4:9092"] # the kafka brokers
  topics: ["TL-Trader"] # the  kafka topics
  group: "group-consumer" # the kafka group
  tls_switch: false # the switch for the ca certification(default closed)
  tls_perm: "certs/kafka/client.pem" # the perm file for ca certification in kafka
  tls_key: "certs/kafka/client.key" # the key file for ca certification in kafka
  tls_ca: "certs/kafka/ca.pem" # the ca file for ca certification in kafka

db:
  user: "postgres" # the username for database
  passwd: "123456" # the passwd for database
  host: "192.168.0.4" # the host for database
  port: "5432" # the port for database
  name: "postgres" # the database name

consul:
  address: "192.168.0.4:8500" # consul address for client api
  directory: "database" # the root directory for different groups of schema
  refresh_time: 10 # the refresh time for loading and updating the configuration from consul

log:
  output_level: "info" # the log level with value in [debug, info, warn, error]
  output_path: "stdout" # a file system path to write the log data to
  rotation_path: "./logs/TL-Data-Consumer.log" # the path to a rotating log file
  rotation_max_size: 100 # the maximum size in megabytes of a log file before it get rotated. It defaults to 100 megabytes.
  rotation_max_age: 30 # the maximum number of days to retain old log files based on the timestamp encoded in their filename
  rotation_max_backups: 1000 # the maximum number of old log files to retain
  json_encoding: false # whether the log is formatted as JSON
