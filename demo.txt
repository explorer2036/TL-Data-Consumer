prepare the environment

1. postgresql database table

DROP TABLE IF EXISTS state;
CREATE TABLE state (
    userid VARCHAR(100) NOT NULL,
    source VARCHAR(100) NOT NULL,
    path VARCHAR(200) NOT NULL,
    type VARCHAR(20) NOT NULL,
    value VARCHAR(10) NOT NULL,
    time TIMESTAMPTZ  NOT NULL,
    timestamp TIMESTAMPTZ  NOT NULL
);

2. kafka broker

create topic: "topic-state"

3. start the consume before make the yaml is correct

copy:  consume and config.yml in the same directory

$ ./consume


4. start the producer for 'topic-state'

Usage of ./provider:
  -a string 
     the brokers of kafka
  -c int
     the count of records (default -1)
  -f int
     the frequency of producing (default 1000)

for example: produce 100000 messages with no sleep

$ ./provider -a http://$ip:$port -f 0 -c 100000

5. monitor: http://$server_ip:8000/metrics  -> total_consume_count, total_insert_count
